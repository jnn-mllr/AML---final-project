{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17153aa2",
   "metadata": {},
   "source": [
    "# Main Notebook\n",
    "This notebook is for the main analysis and experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "48cab40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Courselib path already in sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Enable autoreloading of imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Add the repo root to access the courselib\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "courselib_path = os.path.join(repo_root, \"AppliedML\", \"courselib\")\n",
    "if courselib_path not in sys.path:\n",
    "    sys.path.insert(0, courselib_path)\n",
    "    print(f\"{courselib_path} added to sys.path.\")\n",
    "else:\n",
    "    print(\"Courselib path already in sys.path.\")\n",
    "\n",
    "from utils.preprocessing import encode_features, preprocess_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d08ae2",
   "metadata": {},
   "source": [
    "As this project is supposed to integrate well with the courselib, we have downloaded the current GitHub Repo up to week 11 and our code will be integrated within courselib libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "05c9a498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from local `data/adult.data`...\n"
     ]
    }
   ],
   "source": [
    "from utils.loaders import load_uciadult\n",
    "\n",
    "# ensure the data directory exists / else create it\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# get the data\n",
    "df = load_uciadult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "477c3dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1836\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education-num        0\n",
       "marital-status       0\n",
       "occupation        1843\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital-gain         0\n",
       "capital-loss         0\n",
       "hours-per-week       0\n",
       "native-country     583\n",
       "income               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f8868c",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "1.  **Handle Duplicates**: We remove any duplicate rows from the dataset.\n",
    "2.  **Handle Missing Values**: Instead of removing rows with missing data, we treat the missing values in our categorical columns as a distinct category called 'Missing' as these observations could also contain additional information, expecially when condisering their categorical nature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d11a078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 duplicate observations in the dataset were removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\临时存放\\AML---final-project\\AppliedML\\courselib\\utils\\preprocessing.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna('Missing', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocessing import preprocess_data\n",
    "\n",
    "# preprocessing of  the data\n",
    "df = preprocess_data(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e7d854",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic info about the data set \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b7ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary stats about the variables\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of the target variable\n",
    "plt.figure(figsize=(7, 5))\n",
    "bars = df['income'].value_counts().sort_index().plot(\n",
    "    kind='bar',\n",
    "    color=['blue', 'red'],\n",
    "    edgecolor='black'\n",
    ")\n",
    "plt.title('Class Balance of Income', fontsize=16)\n",
    "plt.xlabel('Income (0 = <=50K, 1 = >50K)', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks([0, 1], ['<=50K', '>50K'], rotation=0, fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f345c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# relationship between income and age\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='age', hue='income', multiple='stack', bins=30, palette='viridis')\n",
    "plt.title('Age Distribution by Income Level', fontsize=16)\n",
    "plt.xlabel('Age', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.legend(title='Income', labels=['>50K', '<=50K'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# income by education\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.countplot(y='education', hue='income', data=df, order=df['education'].value_counts().index, palette='magma')\n",
    "plt.title('Income Level by Education', fontsize=16)\n",
    "plt.xlabel('Count', fontsize=12)\n",
    "plt.ylabel('Education Level', fontsize=12)\n",
    "plt.legend(title='Income', labels=['>50K', '<=50K'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab9232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first glimpse into the data set\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the frequency distribution of native-country\n",
    "df['native-country'].value_counts().head(10).plot(kind='bar')\n",
    "plt.title(\"Top 10 native-country values by frequency\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed1ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference in means of occupation and income, analyze if the target encoding is reasonable\n",
    "df.groupby('occupation')['income'].mean().sort_values().plot(kind='barh')\n",
    "plt.title(\"Mean income by occupation\")\n",
    "plt.xlabel(\"P(income > 50K)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08bc11c",
   "metadata": {},
   "source": [
    "\n",
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17922581",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encoding strategies for each column\n",
    "encoding_strategies = {\n",
    "    'one-hot': ['workclass', 'marital-status', 'relationship', 'race', 'sex'],\n",
    "    'ordinal': {'education': ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th', 'HS-grad',\n",
    "                               'Some-college', 'Bachelors', 'Masters', 'Doctorate', 'Prof-school', 'Assoc-acdm',\n",
    "                                 'Assoc-voc']},\n",
    "    'target': ['income', 'occupation', 'native-country'], # Target column must be the first in the list\n",
    "    # 'frequency': ['native-country'], # compare with target encoding\n",
    "  }\n",
    "\n",
    "# Apply the encoding\n",
    "df_encoded = encode_features(df.copy(), encoding_strategies)\n",
    "\n",
    "# Display the first few rows of the encoded dataframe\n",
    "df_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f450a5a",
   "metadata": {},
   "source": [
    "# Train-Test Set\n",
    "\n",
    "Now we will split the data into train and test sets to prepare for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4683b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split encoded data into train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_encoded.drop('income', axis=1)\n",
    "y = df_encoded['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca6dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Create the model object\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 2. Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 4. Evaluate performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ef1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"RF Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.title(\"Confusion Matrix for Logistic Regression\")\n",
    "plt.show()\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=rf_model.classes_)\n",
    "disp_rf.plot()\n",
    "plt.title(\"Confusion Matrix for Random Forest\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82342a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab493094",
   "metadata": {},
   "source": [
    "\n",
    "## Categorical Feature Analysis\n",
    "\n",
    "To determine the best encoding strategy, we can analyze the relationship between each categorical feature and the target variable (`income`). We'll calculate the mean income for each category to see if there's a natural ordering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887c3ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyze the relationship between categorical features and income\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "if 'income' in categorical_cols:\n",
    "    categorical_cols.remove('income') # Remove target variable\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"--- {col} ---\")\n",
    "    # Group by the column and calculate the mean of the target variable\n",
    "    # We can do this because the target is 0 or 1\n",
    "    print(df.groupby(col)['income'].mean().sort_values(ascending=False))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0fa5e7",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Now we will apply the encoding strategies we defined in our `preprocessing.py` file. We will create a dictionary to specify which encoding to use for each feature type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39029ff5",
   "metadata": {},
   "source": [
    "# What I did. \n",
    "\n",
    "(you can delete this if you agree with these changes, if not, pls let me know which better ideas you have.)\n",
    "\n",
    "in preprocessing.py I did:\n",
    "1.\n",
    "    if 'ordinal' in encoding_strategies:\n",
    "        df_encoded = ordinal_encode(df_encoded, encoding_strategies['ordinal'],{})\n",
    "to\n",
    "    if 'ordinal' in encoding_strategies:\n",
    "        df_encoded = ordinal_encode(df_encoded, encoding_strategies['ordinal'])  \n",
    "\n",
    "2.\n",
    "to strip leading/trailing whitespace from string columns, so in the preprocess_data() I added:\n",
    "\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].str.strip()\n",
    "\n",
    "3.\n",
    "fix “index not in index” problems, so in the target_encode()：\n",
    "    \n",
    "    df.loc[val_indices, encoded_col_name] = val_fold_data[col].map(target_mean_map)\n",
    "to\n",
    "    mapped_values = val_fold_data[col].map(target_mean_map)\n",
    "    df.iloc[val_indices, df.columns.get_loc(encoded_col_name)] = mapped_values\n",
    "\n",
    "in main.ipynb I did:\n",
    "1.just be sure tht everyone can import the data, at beginning I added:\n",
    "\n",
    "from utils.preprocessing import encode_features, preprocess_data\n",
    "\n",
    "2.\n",
    "Remove \"occupation\" from the \"one-hot\" code, and only let it go into the \"target\" code.\n",
    "\n",
    "And for the improvements from Kaggle:\n",
    "\n",
    "1. Convert object columns to category to improve efficiency:\n",
    "\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "But this currently causes many bugs and I haven't found a clean fix yet.\n",
    "\n",
    "2. Apply both frequency encoding and target encoding to native-country for comparison\n",
    "\n",
    "3. Visualize the frequency distribution of high-cardinality categories (e.g., native-country)\n",
    "\n",
    "4. Visualize the average income by occupation to evaluate whether target encoding is appropriate\n",
    "\n",
    "and added the train/test sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applied_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
